{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing jet-images\n",
    "Author: Javier Duarte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `NumPy` array files\n",
    "Here we load the `NumPy` array files. The files are available in a CERNBox: https://cernbox.cern.ch/index.php/s/hMHl6mYSqICOXKl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data/download.tar https://cernbox.cern.ch/index.php/s/hMHl6mYSqICOXKl/download\n",
    "!cd data; tar -xf download.tar\n",
    "!ls data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "# get input numpy arrays\n",
    "inputs = {}\n",
    "inputs['TT'] = glob.glob('data/TT/*job*.npy')\n",
    "inputs['QCD120'] = glob.glob('data/QCD_120to170/*job*.npy')\n",
    "inputs['QCD170'] = glob.glob('data/QCD_170to300/*job*.npy')\n",
    "inputs['QCD300'] = glob.glob('data/QCD_300to470/*job*.npy')\n",
    "inputs['QCD470'] = glob.glob('data/QCD_470to600/*job*.npy')\n",
    "\n",
    "import random\n",
    "fraction_file = 0.3\n",
    "max_file = 1\n",
    "\n",
    "list_params = {}\n",
    "params = {}\n",
    "for key, input_files in inputs.items():\n",
    "    list_params[key] = []\n",
    "    print(key,len(input_files),\"files\")\n",
    "    last_file = int(len(input_files)*fraction_file)+1 if fraction_file>0 else -1\n",
    "    last_file = min(max_file, len(input_files)) if max_file else last_file\n",
    "    if key=='TT': last_file*=20\n",
    "    print(\"Getting\",last_file,\"/\",len(input_files),\"files\")\n",
    "    for in_file in input_files[:last_file]:\n",
    "        try:\n",
    "            print(in_file)\n",
    "            arr = np.load(in_file)\n",
    "            list_params[key].append(arr)\n",
    "        except ValueError:\n",
    "            print('bad file: %s'%in_file)\n",
    "        except IOError:\n",
    "            print('bad io',in_file)\n",
    "    params[key] = np.concatenate(list_params[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to `pandas` DataFrames\n",
    "Here, we convert to `pandas` DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pt_min = 200\n",
    "pt_max = 500\n",
    "\n",
    "df_dict_jet = {}\n",
    "df_dict_jet['TT'] = pd.DataFrame(params['TT'],\n",
    "                                 columns=['run', 'lumi', 'event', 'met', 'sumet', 'rho', 'pthat', \n",
    "                                          'mcweight', 'njet_ak7', 'jet_pt_ak7', 'jet_eta_ak7', \n",
    "                                          'jet_phi_ak7', 'jet_E_ak7', 'jet_msd_ak7', 'jet_area_ak7', \n",
    "                                          'jet_jes_ak7', 'jet_tau21_ak7', 'jet_isW_ak7', 'jet_ncand_ak7',\n",
    "                                          'ak7pfcand_ijet'])\n",
    "df_dict_jet['TT'] = df_dict_jet['TT'].drop_duplicates()\n",
    "df_dict_jet['TT'] =  df_dict_jet['TT'][(df_dict_jet['TT'].jet_pt_ak7 > pt_min) & (df_dict_jet['TT'].jet_pt_ak7 < pt_max) &  (df_dict_jet['TT'].jet_isW_ak7==1)]\n",
    "\n",
    "df_dict_cand = {}\n",
    "df_dict_cand['TT'] = pd.DataFrame(params['TT'],\n",
    "                                  columns=['event', 'jet_pt_ak7', 'jet_isW_ak7', 'ak7pfcand_pt', 'ak7pfcand_eta', 'ak7pfcand_phi', 'ak7pfcand_id', 'ak7pfcand_charge', 'ak7pfcand_ijet'])\n",
    "df_dict_cand['TT'] =  df_dict_cand['TT'][(df_dict_cand['TT'].jet_pt_ak7 > pt_min) & (df_dict_cand['TT'].jet_pt_ak7 < pt_max) &  (df_dict_cand['TT'].jet_isW_ak7==1)]\n",
    "\n",
    "print('number of W jets: %i'%len(df_dict_jet['TT']))\n",
    "\n",
    "for QCDbin in ['QCD120','QCD170','QCD300','QCD470']:\n",
    "    df_dict_jet[QCDbin] = pd.DataFrame(params[QCDbin],columns=['run', 'lumi', 'event', 'met', 'sumet', 'rho', 'pthat', \n",
    "                                                               'mcweight', 'njet_ak7', 'jet_pt_ak7', 'jet_eta_ak7', \n",
    "                                                               'jet_phi_ak7', 'jet_E_ak7', 'jet_msd_ak7', 'jet_area_ak7', \n",
    "                                                               'jet_jes_ak7', 'jet_tau21_ak7', 'jet_isW_ak7', 'jet_ncand_ak7',\n",
    "                                                               'ak7pfcand_ijet'])\n",
    "    df_dict_jet[QCDbin] = df_dict_jet[QCDbin].drop_duplicates()\n",
    "    df_dict_jet[QCDbin] =  df_dict_jet[QCDbin][(df_dict_jet[QCDbin].jet_pt_ak7 > pt_min) & (df_dict_jet[QCDbin].jet_pt_ak7 < 500) &  (df_dict_jet[QCDbin].jet_isW_ak7==0)]\n",
    "    # take every 20th jet just to make the training faster and have a sample roughly the size of W jets\n",
    "    df_dict_jet[QCDbin] = df_dict_jet[QCDbin].iloc[::20, :]\n",
    "    \n",
    "    df_dict_cand[QCDbin] = pd.DataFrame(params[QCDbin],columns=['event', 'jet_pt_ak7', 'jet_isW_ak7', 'ak7pfcand_pt', 'ak7pfcand_eta', 'ak7pfcand_phi', 'ak7pfcand_id', 'ak7pfcand_charge', 'ak7pfcand_ijet'])\n",
    "    df_dict_cand[QCDbin] =  df_dict_cand[QCDbin][(df_dict_cand[QCDbin].jet_pt_ak7 > 200) & (df_dict_cand[QCDbin].jet_pt_ak7 < 500) &  (df_dict_cand[QCDbin].jet_isW_ak7==0)]\n",
    "    \n",
    "    print('number of QCD jets in bin %s: %i'%( QCDbin, len(df_dict_jet[QCDbin])))\n",
    "    \n",
    "df_dict_jet['QCD'] = pd.concat([df_dict_jet['QCD120'],df_dict_jet['QCD170'],df_dict_jet['QCD300'],df_dict_jet['QCD470']])\n",
    "df_dict_cand['QCD'] = pd.concat([df_dict_cand['QCD120'],df_dict_cand['QCD170'],df_dict_cand['QCD300'],df_dict_cand['QCD470']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for rotation and preprocessing jet images\n",
    "Here, we define functions for rotation and preprocessing jet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotation + (possible) reflection needed later\n",
    "def rotate_and_reflect(x,y,w):\n",
    "    rot_x = []\n",
    "    rot_y = []\n",
    "    theta = 0\n",
    "    maxPt = -1\n",
    "    for ix, iy, iw in zip(x, y, w):\n",
    "        dv = np.matrix([[ix],[iy]])-np.matrix([[x.iloc[0]],[y.iloc[0]]])\n",
    "        dR = np.linalg.norm(dv)\n",
    "        thisPt = iw\n",
    "        if dR > 0.35 and thisPt > maxPt:\n",
    "            maxPt = thisPt\n",
    "            # rotation in eta-phi plane c.f  https://arxiv.org/abs/1407.5675 and https://arxiv.org/abs/1511.05190:\n",
    "            # theta = -np.arctan2(iy,ix)-np.radians(90)\n",
    "            # rotation by lorentz transformation c.f. https://arxiv.org/abs/1704.02124:\n",
    "            px = iw * np.cos(iy)\n",
    "            py = iw * np.sin(iy)\n",
    "            pz = iw * np.sinh(ix)\n",
    "            theta = np.arctan2(py,pz)+np.radians(90)\n",
    "            \n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.matrix('{} {}; {} {}'.format(c, -s, s, c))\n",
    "    for ix, iy, iw in zip(x, y, w):\n",
    "        # rotation in eta-phi plane:\n",
    "        #rot = R*np.matrix([[ix],[iy]])\n",
    "        #rix, riy = rot[0,0], rot[1,0]\n",
    "        # rotation by lorentz transformation\n",
    "        px = iw * np.cos(iy)\n",
    "        py = iw * np.sin(iy)\n",
    "        pz = iw * np.sinh(ix)\n",
    "        rot = R*np.matrix([[py],[pz]])\n",
    "        px1 = px\n",
    "        py1 = rot[0,0]\n",
    "        pz1 = rot[1,0]\n",
    "        iw1 = np.sqrt(px1*px1+py1*py1)\n",
    "        rix, riy = np.arcsinh(pz1/iw1), np.arcsin(py1/iw1)\n",
    "        rot_x.append(rix)\n",
    "        rot_y.append(riy)\n",
    "        \n",
    "    # now reflect if leftSum > rightSum\n",
    "    leftSum = 0\n",
    "    rightSum = 0\n",
    "    for ix, iy, iw in zip(x, y, w):\n",
    "        if ix > 0: \n",
    "            rightSum += iw\n",
    "        elif ix < 0:\n",
    "            leftSum += iw\n",
    "    if leftSum > rightSum:\n",
    "        ref_x = [-1.*rix for rix in rot_x]\n",
    "        ref_y = rot_y\n",
    "    else:\n",
    "        ref_x = rot_x\n",
    "        ref_y = rot_y\n",
    "    \n",
    "    return np.array(ref_x), np.array(ref_y)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import keras.backend as K\n",
    "\n",
    "nx = 30 # size of image in eta\n",
    "ny = 30 # size of image in phi\n",
    "xbins = np.linspace(-1.4,1.4,nx+1)\n",
    "ybins = np.linspace(-1.4,1.4,ny+1)\n",
    "\n",
    "def prepareImages(process, df_dict_cand, df_dict_jet):\n",
    "    list_x = []\n",
    "    list_y = []\n",
    "    list_w = []\n",
    "    #if K.image_data_format()=='tf':\n",
    "    #    jet_images = np.zeros((len(df_dict_jet[process]), nx, ny, 1))\n",
    "    #else:        \n",
    "    #    jet_images = np.zeros((len(df_dict_jet[process]), 1, nx, ny))\n",
    "    jet_images = np.zeros((len(df_dict_jet[process]), nx, ny, 1))\n",
    "    \n",
    "    for i in range(0,len(df_dict_jet[process])):\n",
    "        # get the ith jet\n",
    "        df_dict_cand_i = df_dict_cand[process][(df_dict_cand[process]['ak7pfcand_ijet'] == df_dict_jet[process]['ak7pfcand_ijet'].iloc[i]) & (df_dict_cand[process]['event'] == df_dict_jet[process]['event'].iloc[i]) ]\n",
    "        # relative eta\n",
    "        x = df_dict_cand_i['ak7pfcand_eta']-df_dict_cand_i['ak7pfcand_eta'].iloc[0]\n",
    "        # relative phi\n",
    "        y = df_dict_cand_i['ak7pfcand_phi']-df_dict_cand_i['ak7pfcand_phi'].iloc[0]\n",
    "        weights = df_dict_cand_i['ak7pfcand_pt'] # pt of candidate is the weight\n",
    "        x,y = rotate_and_reflect(x,y,weights)\n",
    "        list_x.append(x)\n",
    "        list_y.append(y)\n",
    "        list_w.append(weights)\n",
    "        hist, xedges, yedges = np.histogram2d(x, y, weights=weights, bins=(xbins,ybins))\n",
    "        for ix in range(0,nx):\n",
    "            for iy in range(0,ny):\n",
    "                #if K.image_data_format()=='tf':\n",
    "                #    jet_images[i,ix,iy,0] = hist[ix,iy]\n",
    "                #else:\n",
    "                #    jet_images[i,0,ix,iy] = hist[ix,iy]\n",
    "                jet_images[i,ix,iy,0] = hist[ix,iy]   \n",
    "    return jet_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare jet images\n",
    "Here, we run the pre-defined functions to prepare the jet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_images_dict = {}\n",
    "# 4D tensor (tensorflow backend)\n",
    "# 1st dim is jet index\n",
    "# 2nd dim is eta bin\n",
    "# 3rd dim is phi bin\n",
    "# 4th dim is pt value (or rgb layer, etc.)\n",
    "\n",
    "jet_images_dict['TT'] = prepareImages('TT', df_dict_cand, df_dict_jet)\n",
    "jet_images_dict['QCD'] = prepareImages('QCD', df_dict_cand, df_dict_jet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting jet-images\n",
    "Let's plot some jet-images (individual jets and averaged over all jets)\n",
    "\n",
    "**Question 1:**  Try to plot the average W and QCD jet-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# plot one W jet\n",
    "i = 7\n",
    "plt.figure('W') \n",
    "plt.imshow(jet_images_dict['TT'][i,:,:,0].T, norm=mpl.colors.LogNorm(), origin='lower', interpolation='none')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('pT')\n",
    "plt.xlabel('ieta')\n",
    "plt.ylabel('iphi')\n",
    "plt.show()\n",
    "\n",
    "# plot average W jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one QCD jet\n",
    "i = 12\n",
    "plt.figure() \n",
    "plt.imshow(jet_images_dict['QCD'][i,:,:,0].T, norm=mpl.colors.LogNorm(), origin='lower', interpolation='none')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('pT')\n",
    "plt.xlabel('ieta')\n",
    "plt.ylabel('iphi')\n",
    "plt.show()\n",
    "\n",
    "# plot average QCD jet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our convolutional model\n",
    "**Question 2:** Here we have a relatively simple `Conv2D` model using regularization, batch normalization, max pooling, and a fully connected layer before the ouput. Implement the network defined in https://arxiv.org/pdf/1511.05190.pdf. Compare the performance and number of parameters when using fully connected layers instead of convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dropout, Dense, BatchNormalization, Concatenate\n",
    "from keras.regularizers import l1,l2\n",
    "nx = 30\n",
    "ny = 30\n",
    "inputs = Input(shape=(nx, ny, 1), name='input')\n",
    "x = Conv2D(8, (3, 3), \n",
    "           strides=(1, 1), \n",
    "           padding='same', \n",
    "           activation='relu', \n",
    "           name='conv2d_1', \n",
    "           kernel_regularizer=l2(0.01))(inputs)\n",
    "x = BatchNormalization(momentum=0.6, name='batchnorm_1')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2), name='maxpool2d_1')(x)\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(64, activation='relu', name='dense')(x)\n",
    "outputs = Dense(1, activation='sigmoid', name='output')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into testing and training dataset\n",
    "\n",
    "We will split the data into two parts (one for training+validation and one for testing).\n",
    "**Note:**  We will not apply \"image normalization\" preprocessing: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html.\n",
    "**Question 3:** Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_images = np.concatenate([jet_images_dict['TT'],\n",
    "                             jet_images_dict['QCD']])\n",
    "jet_labels = np.concatenate([np.ones(len(jet_images_dict['TT'])), \n",
    "                             np.zeros(len(jet_images_dict['QCD']))])\n",
    "\n",
    "X = jet_images\n",
    "Y = jet_labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "\n",
    "print('number of W jets for training/validation: %i'%np.sum(Y_train_val==1))\n",
    "print('number of QCD jets for training/validation: %i'%np.sum(Y_train_val==0))\n",
    "\n",
    "print('number of W jets for testing: %i'%np.sum(Y_test==1))\n",
    "print('number of QCD jets for testing: %i'%np.sum(Y_test==0))\n",
    "\n",
    "# early stopping callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# model checkpoint callback\n",
    "# this saves our model architecture + parameters into conv2d_model.h5\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint('conv2d_model.h5', monitor='val_loss', \n",
    "                                   verbose=0, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto', \n",
    "                                   period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training\n",
    "Here, we run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "history = model.fit(X_train_val, Y_train_val, \n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    verbose=0, # switch to 1 for more verbosity\n",
    "                    callbacks=[early_stopping, model_checkpoint], \n",
    "                    validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance\n",
    "Here, we plot the history of the training and the performance in a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plot loss vs epoch\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "ax.plot(history.history['loss'], label='loss')\n",
    "ax.plot(history.history['val_loss'], label='val_loss')\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "\n",
    "# plot accuracy vs epoch\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "ax.plot(history.history['accuracy'], label='accuracy')\n",
    "ax.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('acc')\n",
    "\n",
    "# Plot ROC\n",
    "Y_predict = model.predict(X_test)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "ax.plot(fpr, tpr, lw=2, color='cyan', label='auc = %.3f' % (roc_auc))\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "ax.set_xlim([0, 1.0])\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.set_xlabel('false positive rate')\n",
    "ax.set_ylabel('true positive rate')\n",
    "ax.set_title('receiver operating curve')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
